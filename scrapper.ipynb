{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapper para obtener información de búsqueda de google (LinkdIn y/o Facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexión al navegador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "start_url = 'https://google.com'\n",
    "driver.get(start_url)\n",
    "# Modificar el tamaño de la ventana\n",
    "#driver.execute_script(\"document.body.style.zoom='50%'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivos csv para obtener nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Paterno</th>\n",
       "      <th>Materno</th>\n",
       "      <th>NombreCompleto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bryan Antonio</td>\n",
       "      <td>Polito</td>\n",
       "      <td>Palma</td>\n",
       "      <td>Bryan Antonio Polito Palma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luis</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>Jaramillo</td>\n",
       "      <td>Luis Cruz Jaramillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bryan Antonio</td>\n",
       "      <td>Polito</td>\n",
       "      <td>Palma</td>\n",
       "      <td>Bryan Antonio Polito Palma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>José Alberto</td>\n",
       "      <td>Montán</td>\n",
       "      <td>López</td>\n",
       "      <td>José Alberto Montán López</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andres Manuel</td>\n",
       "      <td>Lopez</td>\n",
       "      <td>Obrador</td>\n",
       "      <td>Andres Manuel Lopez Obrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jorge Luis</td>\n",
       "      <td>Lopez</td>\n",
       "      <td></td>\n",
       "      <td>Jorge Luis Lopez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Juan de Dios</td>\n",
       "      <td>Olivares</td>\n",
       "      <td>Jimenez</td>\n",
       "      <td>Juan de Dios  Olivares Jimenez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bryan Antonio</td>\n",
       "      <td>Polito</td>\n",
       "      <td>Palma</td>\n",
       "      <td>Bryan Antonio Polito Palma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>José Alberto</td>\n",
       "      <td>Montán</td>\n",
       "      <td>López</td>\n",
       "      <td>José Alberto Montán López</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Nombre   Paterno    Materno                  NombreCompleto\n",
       "0  Bryan Antonio    Polito      Palma      Bryan Antonio Polito Palma\n",
       "1           Luis      Cruz  Jaramillo             Luis Cruz Jaramillo\n",
       "2  Bryan Antonio    Polito      Palma      Bryan Antonio Polito Palma\n",
       "3   José Alberto    Montán      López       José Alberto Montán López\n",
       "4  Andres Manuel     Lopez    Obrador     Andres Manuel Lopez Obrador\n",
       "5     Jorge Luis     Lopez                          Jorge Luis Lopez \n",
       "6  Juan de Dios   Olivares    Jimenez  Juan de Dios  Olivares Jimenez\n",
       "7  Bryan Antonio    Polito      Palma      Bryan Antonio Polito Palma\n",
       "8   José Alberto    Montán      López       José Alberto Montán López"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = pd.read_csv('ejemplo.csv', keep_default_na=False) \n",
    "df_3['NombreCompleto'] = df_3.apply(lambda row: f\"{row['Nombre']} {row['Paterno']} {row['Materno']}\", axis=1)\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 href  \\\n",
      "0   https://mx.linkedin.com/in/polito-palma-bryan-...   \n",
      "1    https://mx.linkedin.com/in/bryan-palma-296037272   \n",
      "20  https://m.facebook.com/people/Luis-Cruz-Jarami...   \n",
      "24          https://www.instagram.com/jose_cruz.1320/   \n",
      "25  https://mx.linkedin.com/in/oscar-enrique-cruz-...   \n",
      "26  https://es.linkedin.com/in/alejandra-de-la-cru...   \n",
      "36  https://mx.linkedin.com/in/polito-palma-bryan-...   \n",
      "37   https://mx.linkedin.com/in/bryan-palma-296037272   \n",
      "54  https://mx.linkedin.com/in/jos%C3%A9-alberto-m...   \n",
      "57  https://es-es.facebook.com/JoaquinLopezDoriga/...   \n",
      "\n",
      "                                                 Text  \\\n",
      "0   Bryan Antonio Polito Palma | LinkedInlinkedin....   \n",
      "1   Bryan Palma - Universidad Tecnológica de Méxic...   \n",
      "20  Luis Cruz Jaramillo | Facebookfacebook.comhttp...   \n",
      "24  Jose Luis Cruz Jaramillo (@jose_cruz.1320) • I...   \n",
      "25  Oscar Enrique Cruz Jaramillo - Material Launch...   \n",
      "26  Alejandra de la Cruz Jaramillo - Socio - CRUZJ...   \n",
      "36  Bryan Antonio Polito Palma | LinkedInlinkedin....   \n",
      "37  Bryan Palma - Universidad Tecnológica de Méxic...   \n",
      "54  José Alberto Montán López - Data Scientist - C...   \n",
      "57  VIDEO. Jóvenes mexicanas montan... - Joaquín L...   \n",
      "\n",
      "                                              Resumen  \n",
      "0   Tengo formación en el área de ingeniería de pr...  \n",
      "1   Bryan Antonio Polito Palma. Bioinformatician /...  \n",
      "20  Autores/as. Bryan Antonio Polito Palma Unidad ...  \n",
      "24  §Polito Palma Bryan Antonio. §Hernández Reyes ...  \n",
      "25  Bryan Antonio Pólito Palma 3.- ¿Qué métodos pu...  \n",
      "26  DIEGO ANTONIO. SAN JERONIMO. MIACATLAN ... BRY...  \n",
      "36  Andrés Manuel López Obrador (Tepetitán, Tabasc...  \n",
      "37  Presidente Constitucional de los Estados Unido...  \n",
      "54  27 mar 2023 — ... Juan de Dios Olivares Arreol...  \n",
      "57  Juan José Jiménez Olivares. World Wide Data An...  \n"
     ]
    }
   ],
   "source": [
    "data_ = []\n",
    "data_2 = []\n",
    "for i in df_3['NombreCompleto']:\n",
    "    nombre = driver.find_element(By.XPATH, '//*[@id=\"APjFqb\"]')\n",
    "    nombre.send_keys(i)\n",
    "    nombre.send_keys(Keys.ENTER)\n",
    "        \n",
    "    time.sleep(5)\n",
    "    html_link = driver.page_source\n",
    "    soup = BeautifulSoup(html_link, 'html.parser')\n",
    "\n",
    "    href_tags = soup.find_all('a', href= True)\n",
    "    div_tags = soup.find_all('div', class_=\"VwiC3b\")\n",
    "\n",
    "    for tag in href_tags:\n",
    "        href = tag['href']\n",
    "        text = tag.text\n",
    "\n",
    "        data_.append({'href':href, 'Text': text})\n",
    "\n",
    "    for tag in div_tags:\n",
    "        #div = tag['div']\n",
    "        resumen = tag.text\n",
    "\n",
    "        data_2.append({'Resumen': resumen})\n",
    "        \n",
    "    google = driver.find_element(By.XPATH, '//*[@id=\"logo\"]')\n",
    "    google.click()\n",
    "\n",
    "df= pd.DataFrame(data_)\n",
    "df_2= pd.DataFrame(data_2)\n",
    "\n",
    "    #with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        #print(df)\n",
    "\n",
    "indice = df[df['Text'] == 'Buscar en Ayuda'].index[0]\n",
    "indices_eliminar = df[df['Text'].isin(['Ayuda', 'Privacidad', 'Condiciones'])].index\n",
    "df['Text'] = df['Text'].str.strip()\n",
    "df= df.loc[indice+1:, :].loc[df['href'].str.startswith('http')]\n",
    "df = df[~df['href'].str.contains('translate')]\n",
    "df= df.drop(indices_eliminar)\n",
    "\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = pd.concat([df,df_2], axis=1)\n",
    "df = df.dropna()\n",
    "df = df[df['href'].str.contains('facebook|twitter|instagram|linkedin', case=False)]\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('dataframe.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                href  \\\n",
      "0                       https://lopezobrador.org.mx/   \n",
      "1  https://www.gob.mx/presidencia/estructuras/and...   \n",
      "2  https://www.youtube.com/channel/UCxEgOKuI-n-WO...   \n",
      "3  https://es.wikipedia.org/wiki/Andr%C3%A9s_Manu...   \n",
      "4    https://es-la.facebook.com/lopezobrador.org.mx/   \n",
      "5   https://www.instagram.com/lopezobrador/?hl=es-la   \n",
      "6  https://elpais.com/noticias/andres-manuel-lope...   \n",
      "7      https://www.bbc.com/mundo/topics/cyx5kr6gdy1t   \n",
      "8  https://www.eleconomista.com.mx/personaje/Andr...   \n",
      "\n",
      "                                                Text  \n",
      "0  AMLO – Sitio Oficial de Andrés Manuel López Ob...  \n",
      "1  Andrés Manuel López Obrador | Presidencia de l...  \n",
      "2  Andrés Manuel López Obrador - YouTubeyoutube.c...  \n",
      "3  Andrés Manuel López Obrador - Wikipedia, la en...  \n",
      "4  Andrés Manuel López Obrador - Facebookfacebook...  \n",
      "5  Andrés Manuel López Obrador (@lopezobrador ......  \n",
      "6  Andrés Manuel López Obrador en EL PAÍS - AMLOe...  \n",
      "7  Andrés Manuel López Obrador - BBC News Mundobb...  \n",
      "8  Andrés Manuel López Obrador | El Economistaele...  \n",
      "                                                Text\n",
      "0  Presidente de los Estados Unidos Mexicanos (20...\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data_ = []\n",
    "html_link = driver.page_source\n",
    "soup = BeautifulSoup(html_link, 'html.parser')\n",
    "div = soup.find_all('div', class_=\"kvH3mc BToiNc UK95Uc\")\n",
    "cont = soup.find_all('div', class_ = \"Z26q7c UK95Uc\")\n",
    "\n",
    "for tag in div:\n",
    "    href_tags = tag.find_all('a', href=True)\n",
    "    text = tag.text\n",
    "    \n",
    "    for href_tag in href_tags:\n",
    "        href = href_tag['href']\n",
    "        \n",
    "        data.append({'href': href, 'Text': text})\n",
    "\n",
    "for tag in cont:\n",
    "    span_tags = tag.find_all('span')\n",
    "    \n",
    "    if 'ITHCWe' in span_tag.get('class', []):\n",
    "            continue\n",
    "    \n",
    "    if len (span_tags) > 1:\n",
    "        text = ' '.join(span_tag.text for span_tag in span_tags)\n",
    "    \n",
    "    elif len(span_tags) == 1:\n",
    "        text = span_tags[0].text\n",
    "    else:\n",
    "        text = tag.text.strip()\n",
    "        \n",
    "        \n",
    "data_.append({'Text': text})\n",
    "    \n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_2 = pd.DataFrame(data_)\n",
    "\n",
    "print(df)\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[233], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m df_2\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_)\n\u001b[0;32m     25\u001b[0m \u001b[39m#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39m#print(df)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m indice \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39;49m\u001b[39mText\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mBuscar en Ayuda\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mindex[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     29\u001b[0m indices_eliminar \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin([\u001b[39m'\u001b[39m\u001b[39mAyuda\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrivacidad\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCondiciones\u001b[39m\u001b[39m'\u001b[39m])]\u001b[39m.\u001b[39mindex\n\u001b[0;32m     30\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\DSTHREE\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5320\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5317\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5318\u001b[0m     \u001b[39m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5319\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mcast_scalar_indexer(key, warn_float\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 5320\u001b[0m     \u001b[39mreturn\u001b[39;00m getitem(key)\n\u001b[0;32m   5322\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   5323\u001b[0m     \u001b[39m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5324\u001b[0m     \u001b[39m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5325\u001b[0m     result \u001b[39m=\u001b[39m getitem(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data_ = []\n",
    "html_link = driver.page_source\n",
    "soup = BeautifulSoup(html_link, 'html.parser')\n",
    "href = soup.find_all('a', href= True)\n",
    "div = soup.find_all('div', class_=\"VwiC3b\")\n",
    "class_ = soup.find_all('div', class_=\"kvH3mc BToiNc UK95Uc\")\n",
    "\n",
    "for tag in class_:\n",
    "    href = tag.find_all('a', href = True)\n",
    "    text = tag.text\n",
    "\n",
    "    data.append({'href':href, 'Text': text})\n",
    "\n",
    "for tag in div:\n",
    "    #div = tag['div']\n",
    "    text = tag.text\n",
    "\n",
    "    data_.append({'Text': text})\n",
    "\n",
    "df= pd.DataFrame(data)\n",
    "df.drop\n",
    "df_2= pd.DataFrame(data_)\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    #print(df)\n",
    "\n",
    "indice = df[df['Text'] == 'Buscar en Ayuda'].index[0]\n",
    "indices_eliminar = df[df['Text'].isin(['Ayuda', 'Privacidad', 'Condiciones'])].index\n",
    "df['Text'] = df['Text'].str.strip()\n",
    "df= df.loc[indice+1:, :].loc[df['href'].str.startswith('http')]\n",
    "df = df[~df['href'].str.contains('translate')]\n",
    "df= df.drop(indices_eliminar)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = pd.concat([df,df_2.rename(columns={'Text':'Text2'})], axis=1)\n",
    "#df = df[df['href'].str.contains('facebook|twitter|instagram|linkedin', case=False)]\n",
    "print(df_2)\n",
    "df.to_csv('dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[186], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m nombre\u001b[39m.\u001b[39msend_keys(i)\n\u001b[0;32m      6\u001b[0m nombre\u001b[39m.\u001b[39msend_keys(Keys\u001b[39m.\u001b[39mENTER)\n\u001b[1;32m----> 8\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m html_link \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source\n\u001b[0;32m     10\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(html_link, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data_2 = []\n",
    "for i in df_3['NombreCompleto']:\n",
    "    nombre = driver.find_element(By.XPATH, '//*[@id=\"APjFqb\"]')\n",
    "    nombre.send_keys(i)\n",
    "    nombre.send_keys(Keys.ENTER)\n",
    "        \n",
    "    time.sleep(5)\n",
    "    html_link = driver.page_source\n",
    "    soup = BeautifulSoup(html_link, 'html.parser')\n",
    "\n",
    "    href_tags = soup.find_all('a', href=True)\n",
    "    div_tags = soup.find_all('div', class_=\"VwiC3b\")\n",
    "    class_tags = soup.find_all('div', class_=\"MjjYud\")\n",
    "\n",
    "    for tag in href_tags:\n",
    "        href = tag['href']\n",
    "        text = tag.text\n",
    "        data.append({'href': href, 'Text': text})\n",
    "\n",
    "    for tag in div_tags:\n",
    "        text_2 = tag.text\n",
    "        data_2.append({'Text2': text_2})\n",
    "\n",
    "    google = driver.find_element(By.XPATH, '//*[@id=\"tsf\"]/div[1]/div[1]/div[2]')\n",
    "    google.click()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_2 = pd.DataFrame(data_2)\n",
    "\n",
    "indice = df[df['Text'] == 'Buscar en Ayuda'].index[0]\n",
    "indices_eliminar = df[df['Text'].isin(['Ayuda', 'Privacidad', 'Condiciones'])].index\n",
    "df['Text'] = df['Text'].str.strip()\n",
    "df = df.loc[indice+1:, :]\n",
    "df = df[df['href'].str.startswith('http')]\n",
    "df = df.drop(indices_eliminar)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = pd.concat([df, df_2], axis=1)\n",
    "#df = df[df['href'].str.contains('facebook|twitter|instagram|linkedin', case=False)]\n",
    "df = df.dropna()\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('dataframe.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
